{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c1253d7-e435-43f5-85ca-352f7dfaa15d",
   "metadata": {},
   "source": [
    "# Simulating low-light product inspection\n",
    "\n",
    "This notebook shows how to systematically simulate a change in lighting conditions\n",
    "(i.e. a shift in data distribution), and the effect such a change has on model\n",
    "predictions. The notebook is using the Intel® Geti™ SDK to interact with an\n",
    "Intel® Geti™ server.\n",
    "\n",
    "**Problem description**: For any given project, a data scientist working on it may\n",
    "want to quantify the effect of image distortions on model performance. For example in\n",
    "medical imaging, there is always a certain noise background in the images depending on\n",
    "patient anatomy and radiation dose.\n",
    "\n",
    "In this scenario the customer has set up an anomaly segmentation model to detect\n",
    "fabrication defects on discrete transistors mounted on a printed circuit board. For\n",
    "various reasons, the customer wants to reduce both the light intensity and exposure\n",
    "time in the inspection line. Let's assume the product they are inspecting is sensitive\n",
    "to light so they want to achieve the minimal exposure to light possible, but they\n",
    "still want to detect fabrication defects. How will this affect their anomaly\n",
    "segmentation model? Of course they will do real-world tests before implementing\n",
    "any changes, but is it possible to simulate such a shift in data distribution in\n",
    "advance? *With Intel® Geti™, it is*.\n",
    "\n",
    "**Project type**: Anomaly segmentation\n",
    "\n",
    "**Project name**: Transistor anomaly segmentation\n",
    "\n",
    "\n",
    "### Step 1: Connect to the Intel® Geti™ server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a940f60c-483e-4d08-8f7f-90da72c8150e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "\n",
    "from geti_sdk import Geti\n",
    "\n",
    "env_variables = dotenv_values(dotenv_path=\"../.env\")\n",
    "\n",
    "# The Geti object establishes the connection to the Intel® Geti™ platform\n",
    "geti = Geti(\n",
    "    host=env_variables.get(\"HOST\"),\n",
    "    username=env_variables.get(\"USERNAME\"),\n",
    "    password=env_variables.get(\"PASSWORD\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce7f54f-30e6-4d51-81ad-4b6cd65abee7",
   "metadata": {},
   "source": [
    "### Step 2: Get project\n",
    "The utility function `ensure_trained_anomaly_project` checks that the project required\n",
    "for this notebook is found on the server. If it is not found, the function will create\n",
    "it. To do so, it may have to download the dataset, which could take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa29225f-b2ff-46ed-ad3b-2f74daf9e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geti_sdk.demos import ensure_trained_anomaly_project\n",
    "\n",
    "PROJECT_NAME = \"Transistor anomaly classification\"\n",
    "project = ensure_trained_anomaly_project(geti=geti, project_name=PROJECT_NAME)\n",
    "\n",
    "print(project.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953c76c5-faf0-440c-b80d-b19e2c5e21c6",
   "metadata": {},
   "source": [
    "### Step 3: Get images and annotations\n",
    "Set up ImageClient for the project, get image metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d1a26c-fe88-4163-85bc-00bec6f88040",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geti_sdk.rest_clients import ImageClient\n",
    "\n",
    "image_client = ImageClient(\n",
    "    session=geti.session, workspace_id=geti.workspace_id, project=project\n",
    ")\n",
    "\n",
    "images = image_client.get_all_images()\n",
    "print(f\"Project '{project.name}' contains {len(images)} images\")\n",
    "\n",
    "image_1 = images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8911bc-1105-4590-b71f-9e3b8954333b",
   "metadata": {},
   "source": [
    "Set up AnnotationClient for the project, get annotations for first image in the project and inspect it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5db8516-3f6f-429e-84bf-f244b0ff6d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geti_sdk.rest_clients import AnnotationClient\n",
    "from geti_sdk.utils import show_image_with_annotation_scene\n",
    "\n",
    "annotation_client = AnnotationClient(\n",
    "    session=geti.session, workspace_id=geti.workspace_id, project=project\n",
    ")\n",
    "\n",
    "annotation_1 = annotation_client.get_annotation(image_1)\n",
    "\n",
    "# Inspect annotation for image 1\n",
    "image_1.get_data(geti.session)\n",
    "show_image_with_annotation_scene(image_1, annotation_1, show_in_notebook=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16eccab-feae-43e3-bead-0a55e38cddc9",
   "metadata": {},
   "source": [
    "Get and inspect anomalous image with annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22931107-4846-4ca2-84f2-74ef56f2a1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_2 = images[1]\n",
    "\n",
    "annotation_2 = annotation_client.get_annotation(image_2)\n",
    "\n",
    "# Inspect annotation for image 2\n",
    "image_2.get_data(geti.session)\n",
    "show_image_with_annotation_scene(image_2, annotation_2, show_in_notebook=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6ab6e6-1a94-476d-a7da-8ade2dee165a",
   "metadata": {},
   "source": [
    "### Step 4: Get prediction for anomalous image\n",
    "Set up prediction client, fetch prediction for image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77482bff-6b77-42ce-baff-511cf070839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geti_sdk.rest_clients import PredictionClient\n",
    "\n",
    "prediction_client = PredictionClient(\n",
    "    session=geti.session, workspace_id=geti.workspace_id, project=project\n",
    ")\n",
    "\n",
    "prediction = prediction_client.get_image_prediction(image_2)\n",
    "\n",
    "show_image_with_annotation_scene(image_2, prediction, show_in_notebook=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fccd779-a499-49b0-8c54-2c10fc0bdb3d",
   "metadata": {},
   "source": [
    "### Step 5: Simulate low light conditions\n",
    "To simulate the reduced light intensity, we decrease the overall brightness and add shot noise to the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cc2d07-9f1c-4dc6-b747-eb9d0deb49ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import display_image_in_notebook, simulate_low_light_image\n",
    "\n",
    "# Reduce brightness and add shot noise to\n",
    "# simulate low light intensity and short exposure time\n",
    "new_image_with_noise = simulate_low_light_image(image_2, reduction_factor=0.75)\n",
    "\n",
    "display_image_in_notebook(new_image_with_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3587272d-5aa5-4bf4-8802-57c5801eddda",
   "metadata": {},
   "source": [
    "### Step 6: Get prediction for the modified image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9c0b34-79f6-4b50-b8c5-9a9dab8802cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_noisy_image, noisy_prediction = geti.upload_and_predict_image(\n",
    "    image=new_image_with_noise, project_name=PROJECT_NAME, visualise_output=False\n",
    ")\n",
    "show_image_with_annotation_scene(\n",
    "    new_image_with_noise, noisy_prediction, show_in_notebook=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95f01dc-4cb2-4c0c-9792-848d4cff151b",
   "metadata": {},
   "source": [
    "### Step 7: Simulate a range of different light levels\n",
    "Change the lighting reduction factor from very strong reduction (`reduction_factor=0.1`) to weak reduction (`reduction_factor=0.8`). To inspect the resulting images, it is easiest to open the Geti UI in your browser and have a look at the dataset for the project. The modified images should show up at the bottom of the image list in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38743c5-b446-41e2-9ebd-f336e2cc7fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "start_factor = 0.1\n",
    "stop_factor = 0.8\n",
    "step = 0.1\n",
    "\n",
    "for alpha in np.arange(start_factor, stop_factor, step):\n",
    "    new_image_with_noise = simulate_low_light_image(image_2, reduction_factor=alpha)\n",
    "    image, prediction = geti.upload_and_predict_image(\n",
    "        image=new_image_with_noise, project_name=PROJECT_NAME, visualise_output=False\n",
    "    )\n",
    "    print(\n",
    "        f\"Light reduction factor: {alpha:.1f}. Model prediction: {prediction.annotations[0].labels[0].name}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3c0df1-6287-42bb-af0c-69db1d402eff",
   "metadata": {},
   "source": [
    "## Model re-training for low light conditions\n",
    "Ok, so now we know that the *existing* model can still find anomalies, even in low light conditions. But, of course this is not a fair comparison since the low light images are not part of the training set for that model. Could we simulate training a completely new model on a low-light dataset? Yes we can!\n",
    "\n",
    "### Step 8: Create a new project\n",
    "Create a new project dedicated to images with a certain lighting reduction factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbeddc1-6906-48b5-aff6-8f668d274aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geti_sdk.rest_clients import ProjectClient\n",
    "\n",
    "project_client = ProjectClient(session=geti.session, workspace_id=geti.workspace_id)\n",
    "\n",
    "LIGHT_REDUCTION_FACTOR = 0.5\n",
    "\n",
    "new_project = project_client.get_or_create_project(\n",
    "    project_name=PROJECT_NAME + f\" light reduction factor {LIGHT_REDUCTION_FACTOR:.1f}\",\n",
    "    project_type=\"anomaly_classification\",\n",
    "    labels=[[]],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6988f5e8-ce49-4137-a72d-cc1d28561c8a",
   "metadata": {},
   "source": [
    "### Step 9: Modify all images data and annotations\n",
    "\n",
    "##### Loop over the existing images and:\n",
    "  1. Create new image with simulated low light conditions\n",
    "  2. Get existing annotation for image\n",
    "  3. Apply existing annotation to simulated image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec74bef-b17f-443e-a779-f12a38b66778",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image_client = ImageClient(\n",
    "    session=geti.session, workspace_id=geti.workspace_id, project=new_project\n",
    ")\n",
    "new_annotation_client = AnnotationClient(\n",
    "    session=geti.session, workspace_id=geti.workspace_id, project=new_project\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Converting and uploading images and annotations to project '{new_project.name}'...\"\n",
    ")\n",
    "for ii, image in enumerate(images):\n",
    "    annotation = annotation_client.get_annotation(image)\n",
    "    numpy_image = image.get_data(geti.session)\n",
    "    new_image = simulate_low_light_image(\n",
    "        numpy_image, reduction_factor=LIGHT_REDUCTION_FACTOR\n",
    "    )\n",
    "    new_sc_image = new_image_client.upload_image(new_image)\n",
    "    new_annotation = annotation.map_labels(labels=new_project.get_all_labels())\n",
    "    new_annotation_client.upload_annotation(\n",
    "        annotation_scene=new_annotation, media_item=new_sc_image\n",
    "    )\n",
    "    if (ii + 1) % 25 == 0:\n",
    "        print(\n",
    "            f\"{ii+1} images and annotations converted and uploaded successfully. Processing...\"\n",
    "        )\n",
    "\n",
    "print(\"Conversion complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15414ee5-9437-48e4-8d01-29916e2c9448",
   "metadata": {},
   "source": [
    "### Step 10: Start training job and monitor progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd62a54-6add-4f75-82e4-1a4f1a6ec8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geti_sdk.rest_clients import TrainingClient\n",
    "\n",
    "training_client = TrainingClient(\n",
    "    session=geti.session, workspace_id=geti.workspace_id, project=new_project\n",
    ")\n",
    "\n",
    "job = training_client.train_task(task=0)\n",
    "\n",
    "training_client.monitor_jobs([job])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1130f08a-c104-48c9-91eb-65252e44a43c",
   "metadata": {},
   "source": [
    "### Step 11: Comparing the two models\n",
    "Now that we have a trained model for both projects, we can compare the performance between the two. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eea775-0691-4f8d-909f-18be019f79b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geti_sdk.rest_clients import ModelClient\n",
    "\n",
    "model_client = ModelClient(\n",
    "    session=geti.session, workspace_id=geti.workspace_id, project=project\n",
    ")\n",
    "new_model_client = ModelClient(\n",
    "    session=geti.session, workspace_id=geti.workspace_id, project=new_project\n",
    ")\n",
    "\n",
    "model = model_client.get_all_active_models()[0]\n",
    "new_model = new_model_client.get_all_active_models()[0]\n",
    "\n",
    "print(\n",
    "    f\"Performance of the model for the unmodified, original project: {model.performance.score}\"\n",
    ")\n",
    "print(\n",
    "    f\"Performance of the model for new project with light reduction factor of {LIGHT_REDUCTION_FACTOR}: {new_model.performance.score}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0e2fdb-2e4c-48ff-84e6-c8a8bb4221ea",
   "metadata": {},
   "source": [
    "### Finally, cleaning up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee3bb20-b70d-4652-995b-d27c2e8830d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning up the first project by removing the uploaded images that don't have annotations\n",
    "\n",
    "images_to_delete = []\n",
    "for image in image_client.get_all_images():\n",
    "    if annotation_client.get_annotation(image) is None:\n",
    "        images_to_delete.append(image)\n",
    "image_client.delete_images(images_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c04ab2-89d7-430a-a1f4-b88508f50a68",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Cleaning up the second project by removing it from the server\n",
    "project_client.delete_project(project=new_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8529c1ae-4412-406a-9a42-4e4ef00f8169",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
