{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fda1465-41c3-45f3-8d9e-868473e82ad9",
   "metadata": {},
   "source": [
    "# Creating a project from an existing dataset\n",
    "In notebook [002 create project from dataset](002_create_project_from_dataset.ipynb) we saw how to create a single task project from an existing dataset, and upload images and annotations to it. \n",
    "\n",
    "In this notebook we'll expand on this and create a pipeline project with two subsequent tasks instead. We'll annotate the tasks by grouping some of the classes in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35717528-ee7e-41be-af63-7451e6c169f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As usual we'll connnect to the platform first, using the credentials from the .env file\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "from geti_sdk import Geti\n",
    "\n",
    "env_variables = dotenv_values(dotenv_path=\".env\")\n",
    "\n",
    "if not env_variables:\n",
    "    print(\n",
    "        \"Unable to load login details from .env file, please make sure the file exists at the root of the notebooks directory.\"\n",
    "    )\n",
    "\n",
    "geti = Geti(\n",
    "    host=env_variables.get(\"HOST\"),\n",
    "    username=env_variables.get(\"USERNAME\"),\n",
    "    password=env_variables.get(\"PASSWORD\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294b9b41-1577-4955-9248-694a05719dbe",
   "metadata": {},
   "source": [
    "### Getting the COCO dataset\n",
    "As we did in notebook [002](002_create_project_from_dataset.ipynb) before, we'll use the MS COCO dataset. We get the path to it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ee2b8f-6f79-4916-857b-9af585848d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geti_sdk.utils import get_coco_dataset\n",
    "\n",
    "COCO_PATH = get_coco_dataset(dataset_path=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903244cd-70ab-4990-a55b-1516ad4d6165",
   "metadata": {},
   "source": [
    "### Reading the dataset\n",
    "Again as before, we'll create an annotation reader to read the dataset. However, since in this case we'll be annotating two different tasks, we'll also need two annotation readers. Each will provide the annotations for one of the tasks in the pipeline, with different labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c1033b-2856-46c0-b513-7b41de0b128e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geti_sdk.annotation_readers import DatumAnnotationReader\n",
    "\n",
    "annotation_reader_task_1 = DatumAnnotationReader(\n",
    "    base_data_folder=COCO_PATH, annotation_format=\"coco\"\n",
    ")\n",
    "annotation_reader_task_2 = DatumAnnotationReader(\n",
    "    base_data_folder=COCO_PATH, annotation_format=\"coco\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3652dcd5-b9c6-4eae-814e-5489804772f8",
   "metadata": {},
   "source": [
    "### Selecting labels and project type\n",
    "As before, we'll use a subset of the COCO dataset for simplicity. Let's create a multi-task project of type: `detection_to_classification`. To do so, we have to prepare the annotation readers in a specific way.\n",
    "\n",
    "Let's use a single label 'animal' for the detection task. The classification task will use the labels 'Domestic' and 'Wild', to try to discriminate these two groups of animals.\n",
    "\n",
    "First, we'll have to specify which animals we consider 'Domestic', and which 'Wild'. This is done in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d7ab28-11e3-43bd-ba8a-cf111b9c209b",
   "metadata": {},
   "outputs": [],
   "source": [
    "domestic_animals = [\"dog\", \"cat\", \"horse\"]\n",
    "wild_animals = [\"elephant\", \"giraffe\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d270dfe-89a1-4b1f-8a93-14edaf2d161a",
   "metadata": {},
   "source": [
    "#### Preparing the detection annotation reader\n",
    "Now that we know the labels of interest, we can filter the dataset for the detection annotation reader and group the classes to a single 'animal' label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2b3428-b4c4-4421-83cb-0726502c9fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = domestic_animals + wild_animals\n",
    "annotation_reader_task_1.filter_dataset(labels=all_labels, criterion=\"OR\")\n",
    "annotation_reader_task_1.group_labels(labels_to_group=all_labels, group_name=\"animal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ee0c90-7a87-4163-a063-f2a057a65538",
   "metadata": {},
   "source": [
    "#### Preparing the classification annotation reader\n",
    "For the classification task, we apply the same filter but we group the classes differently, using the 'domestic' and 'wild' labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7d6e23-799b-4e1c-9d0e-3c7f10812020",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_reader_task_2.filter_dataset(labels=all_labels, criterion=\"OR\")\n",
    "annotation_reader_task_2.group_labels(\n",
    "    labels_to_group=domestic_animals, group_name=\"domestic\"\n",
    ")\n",
    "annotation_reader_task_2.group_labels(labels_to_group=wild_animals, group_name=\"wild\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ab5cc0-3db7-4c96-9fa0-65df9464a4ae",
   "metadata": {},
   "source": [
    "## Creating the project\n",
    "Now that we have determined the project_type and prepared the annotation readers, we can use the `Geti` to create the project and upload the images and annotations.\n",
    "\n",
    "The Geti class provides a convenience method `geti.create_task_chain_project_from_dataset` that creates the project and uploads the images and annotations. It is very similar to the method we used to create a project in notebook [002](002_create_project_from_dataset.ipynb), but instead of taking the parameter `annotation_reader`, it takes a `label_source_per_task` instead. This parameter should receive a list of label sources, one entry per task. For each task, the source can either be an annotation reader, a list of label names or a list of dictionaries specifying label properties, as we used at the end of notebook [001](001_create_project.ipynb). \n",
    "\n",
    "Passing lists of label names or properties can be useful if you don't have annotations available for one of the tasks in the pipeline, but you do know what labels you'd like that task to have and you plan on annotating that tasks through the platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73a6646-1b1d-4997-b986-c8f75bbe0c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"COCO multitask animal demo\"\n",
    "PROJECT_TYPE = \"detection_to_classification\"\n",
    "\n",
    "project = geti.create_task_chain_project_from_dataset(\n",
    "    project_name=PROJECT_NAME,\n",
    "    project_type=PROJECT_TYPE,\n",
    "    path_to_images=COCO_PATH,\n",
    "    label_source_per_task=[annotation_reader_task_1, annotation_reader_task_2],\n",
    "    number_of_images_to_upload=100,\n",
    "    number_of_images_to_annotate=90,\n",
    "    enable_auto_train=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf0f98f-e623-4bde-be20-fed5ed9a4d7e",
   "metadata": {},
   "source": [
    "That's it! The project has been created and should now have started training the detection task. Let's have a look at the project summary, even though there shouldn't be any surprises there at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142e6932-0b3e-4a32-b5e2-bcc655dd807e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(project.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32050c75-56ec-4489-9a6d-7452a0d80345",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
